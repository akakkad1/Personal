{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akakkad1/Personal/blob/code-ridge/AIML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNlTyxMrX9Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI and ML Lessons 1-20**"
      ],
      "metadata": {
        "id": "P0qWI9bSYDUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prerequisites\n",
        "-------------------------\n",
        "1. Click the \"Terminal\" icon\n",
        "2. On the command line, type \"pip -h\"\n",
        "3. If no errors occur, type \"pip install torch\".\n",
        "4. Once the whole command finishes running, run the bottom code block to confirm it works"
      ],
      "metadata": {
        "id": "H3FGyss8Olzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"it works\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIXgRjXWP8rU",
        "outputId": "8766fbfc-cd40-49e4-ccbd-03072c4fdb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it works\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors\n",
        "-------------------------\n",
        "A tensor is just a container for numbers. Start simple:\n",
        "- 0-D: one number (a scalar), like 7.\n",
        "- 1-D: a list of numbers (a vector), like [1,2,3].\n",
        "- 2-D: a table of numbers (a matrix), like rows & columns.\n",
        "- 3-D+: think stacks of matrices (e.g., images with color channels).\n",
        "\n",
        "Why PyTorch Tensors?\n",
        "- They act like NumPy arrays BUT can use the GPU to go fast.\n",
        "- You can easily check their size with .shape and how many dims with .ndim."
      ],
      "metadata": {
        "id": "_ag3Gne0YzLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# --- Example (follow along) ---\n",
        "scalar = torch.tensor(5.0)\n",
        "print(\"Scalar:\", scalar, \"| dims:\", scalar.ndim)\n",
        "\n",
        "vec = torch.tensor([1, 2, 3])\n",
        "print(\"Vector:\", vec, \"| dims:\", vec.ndim)\n",
        "\n",
        "mat = torch.tensor([[1, 2], [3, 4]])\n",
        "print(\"Matrix:\\n\", mat, \"\\n| dims:\", mat.ndim)"
      ],
      "metadata": {
        "id": "QxUYIXeZZZAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity (fill the blanks) ---\n",
        "# Make a 1-D tensor [10, 20, 30, 40] and print its ndim and shape.\n",
        "my_vec = torch.tensor([_, _, _, _])\n",
        "print(\"my_vec:\", my_vec, \"| dims:\", my_vec._, \"| shape:\", my_vec._)"
      ],
      "metadata": {
        "id": "QO0jLxQ9ZecU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dtype & Device\n",
        "--------------\n",
        "- dtype (datatype) is the \"type\" of the numbers (float32, int64, etc).\n",
        "- device is WHERE the tensor lives: 'cpu' or 'cuda' (GPU).\n",
        "- Moving a tensor: tensor.to(device). If no GPU, CPU is fine.\n",
        "\n",
        "Why care?\n",
        "- Models expect certain dtypes (e.g., float32 for inputs).\n",
        "- Training on GPU (if available) can be much faster."
      ],
      "metadata": {
        "id": "1UiN6tscZhzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example ---\n",
        "x = torch.arange(5, dtype=torch.float32)\n",
        "print(\"x:\", x, \"| dtype:\", x.dtype)\n",
        "\n",
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "x_gpu = x.to(dev)\n",
        "print(\"Moved to:\", x_gpu.device)"
      ],
      "metadata": {
        "id": "fXSBeUWzcquR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Create an int64 tensor [3, 6, 9], then move it to dev.\n",
        "y = torch.tensor([_, _, _], dtype=torch._)\n",
        "y_dev = y.to(_)\n",
        "print(\"y_dev:\", y_dev, \"| device:\", y_dev.device)"
      ],
      "metadata": {
        "id": "GX745uGCctcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shapes & Broadcasting\n",
        "---------------------\n",
        "- shape tells you the rows/cols/etc. Example: (2,3) is 2 rows, 3 columns.\n",
        "- Broadcasting lets PyTorch auto-match shapes when doing math.\n",
        "  Example: (2,3) + (3,) -> (2,3), by adding the small one to each row.\n",
        "\n",
        "Reshaping:\n",
        "- Use .reshape(new_shape) to view data in a different shape."
      ],
      "metadata": {
        "id": "QknXOIX1czmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example ---\n",
        "A = torch.arange(6).reshape(2, 3)\n",
        "b = torch.tensor([10, 20, 30])   # shape (3,)\n",
        "C = A + b                        # broadcast across rows\n",
        "print(\"A:\\n\", A, \"\\nC:\\n\", C)"
      ],
      "metadata": {
        "id": "avWniZYjc2ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# 1) Make D of shape (3,2) from torch.arange(6)\n",
        "D = torch.arange(6)._( _, _ )\n",
        "print(\"D shape:\", D.shape)\n",
        "\n",
        "# 2) Add a vector v = [1, 0] to each row of D via broadcasting\n",
        "v = torch.tensor([_, _])\n",
        "E = D _ v\n",
        "print(\"E:\\n\", E)"
      ],
      "metadata": {
        "id": "PqZxkCI5c5zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing & Slicing\n",
        "------------------\n",
        "- Index rows/cols like Python lists.\n",
        "- A[:, 0] means \"all rows, first column\".\n",
        "- A[0] or A[0, :] means \"first row\".\n",
        "\n",
        "Use cases:\n",
        "- Picking features (columns) from data.\n",
        "- Looking at subsets (mini-batches)."
      ],
      "metadata": {
        "id": "alLwT3GMc8vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example ---\n",
        "M = torch.tensor([[5, 6, 7], [8, 9, 10]])\n",
        "first_row = M[0]\n",
        "col2 = M[:, 1]\n",
        "print(\"first_row:\", first_row)\n",
        "print(\"second column:\", col2)"
      ],
      "metadata": {
        "id": "iNTfbt2mdCKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# From N, get last row and last column.\n",
        "N = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "last_row = N[_]\n",
        "last_col = N[:, _]\n",
        "print(\"last_row:\", last_row, \"| last_col:\", last_col)"
      ],
      "metadata": {
        "id": "HtVu2BkndIFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning = Adjusting Numbers\n",
        "----------------------------\n",
        "Imagine you guess a number w to match a target. If your guess is off,\n",
        "you nudge w to be better next time. Autograd helps compute HOW to nudge w.\n",
        "\n",
        "Key idea:\n",
        "- requires_grad=True tells PyTorch to track math on that tensor.\n",
        "- loss.backward() computes “gradient”: the recommended nudge direction.\n",
        "- With torch.no_grad(): temporarily turns tracking OFF for manual updates."
      ],
      "metadata": {
        "id": "zcGAJJZ0dKfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example ---\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "target = 3.0\n",
        "loss = (w - target)**2\n",
        "loss.backward()             # compute gradient in w.grad\n",
        "with torch.no_grad():\n",
        "    w = w - 0.1 * w.grad    # take a small step\n",
        "print(\"updated w:\", w.item())"
      ],
      "metadata": {
        "id": "twhko27zdUJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Make w0 start at 10.0, compute loss to target=2.0, then take one update step.\n",
        "w0 = torch.tensor(10.0, requires_grad=_)\n",
        "loss0 = (w0 - _ ) ** 2\n",
        "loss0._()\n",
        "with torch._():\n",
        "    w0 = w0 - 0.1 * _\n",
        "print(\"w0 after step:\", w0.item())"
      ],
      "metadata": {
        "id": "44E7OfP7dXVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Layers (Mixing Inputs)\n",
        "-----------------------------\n",
        "A Linear layer does: output = input @ W^T + b.\n",
        "- Think: take features and mix them into new numbers.\n",
        "- It’s the basic building block of neural networks.\n",
        "\n",
        "We create a tiny model with one Linear layer."
      ],
      "metadata": {
        "id": "IJtyZyVqdVge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# --- Example ---\n",
        "lin = nn.Linear(3, 2)        # 3 inputs -> 2 outputs\n",
        "x = torch.randn(4, 3)        # batch of 4 rows\n",
        "y = lin(x)\n",
        "print(\"Output shape:\", y.shape)  # (4,2)"
      ],
      "metadata": {
        "id": "3odEjLC5dfwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Make a Linear layer that maps 5 features to 1 output, then run it on rand(2,5).\n",
        "layer = nn._(_, _)\n",
        "x2 = torch.randn(_, _)\n",
        "y2 = layer(x2)\n",
        "print(\"y2 shape:\", y2.shape)"
      ],
      "metadata": {
        "id": "k8Ngokp_dnVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activations (Add Curves)\n",
        "------------------------\n",
        "Without activations, stacking Linear layers is still just a straight line.\n",
        "Activations (ReLU, Sigmoid, Tanh) add curves so models can learn complex shapes.\n",
        "\n",
        "- ReLU(x) = max(0, x) keeps positives, zeros-out negatives.\n",
        "- Sigmoid squashes values to (0,1).\n",
        "- Tanh squashes values to (-1,1)."
      ],
      "metadata": {
        "id": "znhrNNyvdtaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example ---\n",
        "vals = torch.linspace(-2, 2, steps=5)\n",
        "print(\"ReLU:\", nn.ReLU()(vals))\n",
        "print(\"Sigmoid:\", nn.Sigmoid()(vals))\n",
        "print(\"Tanh:\", nn.Tanh()(vals))"
      ],
      "metadata": {
        "id": "QhaafK5SdxH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Apply ReLU to arr and print it.\n",
        "arr = torch.tensor([-3.0, -1.0, 0.0, 2.0])\n",
        "relu = nn._()\n",
        "out = relu(_)\n",
        "print(\"ReLU(arr):\", out)"
      ],
      "metadata": {
        "id": "8Av05famd0Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss = How Wrong Are We?\n",
        "------------------------\n",
        "Loss is a single number: lower is better.\n",
        "- Regression: MSE (mean squared error) compares numbers to numbers.\n",
        "- Classification: CrossEntropy compares predicted scores to class labels.\n",
        "\n",
        "We’ll compute both on tiny examples."
      ],
      "metadata": {
        "id": "UgVE7vZHdtXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example ---\n",
        "# MSE for regression\n",
        "pred = torch.tensor([2.0, 4.0])\n",
        "true = torch.tensor([3.0, 5.0])\n",
        "mse = nn.MSELoss()\n",
        "print(\"MSE:\", mse(pred, true).item())"
      ],
      "metadata": {
        "id": "kIgMgIsueNDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# CrossEntropy for 2-class example (logits and class indices)\n",
        "logits = torch.tensor([[2.0, 0.5],[0.1, 1.5]])\n",
        "labels = torch.tensor([0, 1])\n",
        "ce = nn._()\n",
        "print(\"CE:\", ce(_, _).item())"
      ],
      "metadata": {
        "id": "D3nlVQH8ePNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizers = Automatic Nudgers\n",
        "------------------------------\n",
        "Instead of updating weights by hand, an optimizer does it for you.\n",
        "Loop:\n",
        "  1) optimizer.zero_grad()\n",
        "  2) compute loss\n",
        "  3) loss.backward()\n",
        "  4) optimizer.step()\n",
        "Common choices: SGD, Adam."
      ],
      "metadata": {
        "id": "1c8cUYTtdlL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# --- Example ---\n",
        "w = torch.tensor(5.0, requires_grad=True)\n",
        "opt = optim.SGD([w], lr=0.1)\n",
        "target = torch.tensor(1.0)\n",
        "\n",
        "for _ in range(3):\n",
        "    opt.zero_grad()\n",
        "    loss = (w - target).pow(2)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    print(\"w:\", w.item(), \"loss:\", loss.item())"
      ],
      "metadata": {
        "id": "ja0lyqMIe6b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Use Adam optimizer (lr 0.05) on a new parameter p starting at 0.0 for 2 steps.\n",
        "p = torch.tensor(0.0, requires_grad=True)\n",
        "opt2 = optim._([p], lr=_)\n",
        "for _ in range(2):\n",
        "    opt2.zero_grad()\n",
        "    loss2 = (p - 4.0) ** 2\n",
        "    loss2._()\n",
        "    opt2._()\n",
        "print(\"p:\", p.item())"
      ],
      "metadata": {
        "id": "HvosSU6ze9um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets & DataLoaders\n",
        "----------------------\n",
        "Dataset: how to get one example (x,y) by index.\n",
        "DataLoader: gives you mini-batches automatically and can shuffle.\n",
        "\n",
        "Batching helps training be faster and more stable."
      ],
      "metadata": {
        "id": "vdrfuxOmdkmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# --- Example ---\n",
        "class TinyDS(Dataset):\n",
        "    def __init__(self):\n",
        "        self.x = torch.arange(12).float().reshape(6, 2)\n",
        "        self.y = (self.x.sum(dim=1) > 5).long()  # 0/1 labels\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i): return self.x[i], self.y[i]\n",
        "\n",
        "loader = DataLoader(TinyDS(), batch_size=3, shuffle=True)\n",
        "for xb, yb in loader:\n",
        "    print(\"batch:\", xb.shape, yb.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "RWCxA9CAfX9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Build a DataLoader with batch_size 2 and print the first batch shapes.\n",
        "my_loader = DataLoader(TinyDS(), batch_size=_, shuffle=_)\n",
        "for xb, yb in my_loader:\n",
        "    print(\"my batch:\", xb.shape, yb.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "Ui9wv291fZ7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop (The Recipe)\n",
        "--------------------------\n",
        "For each epoch:\n",
        "  - model.train()\n",
        "  - for each batch: zero_grad -> forward -> loss -> backward -> step\n",
        "\n",
        "This is the heartbeat of training.\n",
        "\n",
        "We’ll make a tiny model and run a few steps."
      ],
      "metadata": {
        "id": "lntDOfaFfncP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# --- Example ---\n",
        "X = torch.randn(80, 4)\n",
        "y = (X.sum(1) > 0).long()\n",
        "model = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 2))\n",
        "opt = optim.SGD(model.parameters(), lr=0.1)\n",
        "crit = nn.CrossEntropyLoss()\n",
        "loader = DataLoader(TensorDataset(X, y), batch_size=16, shuffle=True)\n",
        "\n",
        "for epoch in range(2):\n",
        "    total = 0.0\n",
        "    for xb, yb in loader:\n",
        "        opt.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = crit(logits, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total += loss.item()\n",
        "    print(\"epoch\", epoch, \"avg loss\", total/len(loader))"
      ],
      "metadata": {
        "id": "m1UykqMXfwwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Change hidden size to 4 and learning rate to 0.05, and train 1 epoch.\n",
        "model2 = nn.Sequential(nn.Linear(4, _), nn.ReLU(), nn.Linear(_, 2))\n",
        "opt2 = optim.SGD(model2.parameters(), lr=_)"
      ],
      "metadata": {
        "id": "-B-hOiC2f1Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save & Load Weights\n",
        "-------------------\n",
        "- Save: torch.save(model.state_dict(), \"file.pth\")\n",
        "- Load: state = torch.load(\"file.pth\"); model.load_state_dict(state)\n",
        "This keeps your learned knowledge for later."
      ],
      "metadata": {
        "id": "i11_OKBLgMiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# --- Example ---\n",
        "m = nn.Sequential(nn.Linear(3, 4), nn.ReLU(), nn.Linear(4, 2))\n",
        "torch.save(m.state_dict(), \"demo_weights.pth\")\n",
        "m2 = nn.Sequential(nn.Linear(3, 4), nn.ReLU(), nn.Linear(4, 2))\n",
        "state = torch.load(\"demo_weights.pth\")\n",
        "m2.load_state_dict(state)\n",
        "print(\"Loaded OK:\", set(m.state_dict().keys()) == set(m2.state_dict().keys()))"
      ],
      "metadata": {
        "id": "8a-dqXj3gOlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Save m2’s weights to \"my_model.pth\"\n",
        "torch._(m2.state_dict(), \"my_model.pth\")"
      ],
      "metadata": {
        "id": "xT8blL3tgVeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV to Tensors\n",
        "--------------\n",
        "Typical table: columns = features (inputs) + a label (target).\n",
        "Steps:\n",
        "1) Read CSV with pandas.\n",
        "2) Pick feature columns (e.g., weight, height, claws).\n",
        "3) Pick target column (e.g., species_id).\n",
        "4) Convert to tensors with correct dtypes.\n",
        "\n",
        "Note: classification labels should be integer (long)."
      ],
      "metadata": {
        "id": "jjM6bFGBgc3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Example ---\n",
        "# Suppose animals.csv has columns: weight, height, claws, label\n",
        "# df = pd.read_csv(\"animals.csv\")    # uncomment to use real file\n",
        "# Here we’ll fake a tiny DataFrame:\n",
        "df = pd.DataFrame({\n",
        "    \"weight\":[2.0,3.5,5.1],\n",
        "    \"height\":[10.0,12.0,8.0],\n",
        "    \"claws\":[1,0,1],\n",
        "    \"label\":[0,1,0]\n",
        "})\n",
        "\n",
        "X = torch.tensor(df[[\"weight\",\"height\",\"claws\"]].values).float()\n",
        "y = torch.tensor(df[\"label\"].values).long()\n",
        "print(\"X:\", X.shape, \"y:\", y.shape, \"y dtype:\", y.dtype)"
      ],
      "metadata": {
        "id": "7zSndSrngedc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Replace \"_\" with your actual CSV path and label column name.\n",
        "csv_path = \"_\"\n",
        "target_col = \"_\"\n",
        "# real_df = pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "WdLPuL-cgqco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize & Split\n",
        "-----------------\n",
        "Why normalize?\n",
        "- Features vary wildly (e.g., height in cm vs claws as 0/1).\n",
        "- Normalizing (x - mean)/std puts them on similar scales.\n",
        "\n",
        "Split:\n",
        "- Keep 20% as validation to check how well you generalize."
      ],
      "metadata": {
        "id": "U3KEuRjXhLYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example ---\n",
        "X = torch.tensor([[2.0, 10.0, 1.0],\n",
        "                  [3.0, 12.0, 0.0],\n",
        "                  [5.0,  8.0, 1.0]])\n",
        "y = torch.tensor([0, 1, 0]).long()\n",
        "mean, std = X.mean(0, keepdim=True), X.std(0, keepdim=True)\n",
        "Xn = (X - mean) / (std + 1e-8)\n",
        "n = Xn.shape[0]; n_tr = int(0.8*n)\n",
        "Xtr, ytr = Xn[:n_tr], y[:n_tr]\n",
        "Xva, yva = Xn[n_tr:], y[n_tr:]\n",
        "print(\"train:\", Xtr.shape, \"| val:\", Xva.shape)"
      ],
      "metadata": {
        "id": "WClPiviShOQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Compute mean/std of A (3x3), normalize to An, and split first 2 rows as train.\n",
        "A = torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0],[7.0,8.0,9.0]])\n",
        "m = A._(0, keepdim=True)\n",
        "s = A._(0, keepdim=True)\n",
        "An = (A - _) / (_ + 1e-8)\n",
        "Atr, Ava = An[:_], An[_:]\n",
        "print(\"Atr shape:\", Atr.shape, \"Ava shape:\", Ava.shape)"
      ],
      "metadata": {
        "id": "TE5yH52NhXu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Small MLP for Tabular Data\n",
        "----------------------------\n",
        "We'll build: Linear -> ReLU -> Linear\n",
        "- Input dim = number of features (e.g., 3).\n",
        "- Hidden dim = a small number (e.g., 8).\n",
        "- Output dim = number of classes (e.g., 3 species).\n",
        "\n",
        "This is a good starter architecture."
      ],
      "metadata": {
        "id": "XkXdliXvhee9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Example ---\n",
        "input_dim, hidden, out_dim = 3, 8, 3\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(input_dim, hidden),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden, out_dim)\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "cfTX-slphj-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Activity ---\n",
        "# Change hidden size to 4 and output classes to 2.\n",
        "model2 = nn.Sequential(\n",
        "    nn.Linear(3, _),\n",
        "    nn._(),\n",
        "    nn.Linear(_, _)\n",
        ")\n",
        "print(model2)"
      ],
      "metadata": {
        "id": "Utewbn7YhnKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Template"
      ],
      "metadata": {
        "id": "xJLCsjz0UsDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a template for a simple chatbot using Google Gemini  model.\n",
        "You can customize it however you like.\n",
        "\n",
        "Make sure to install the OpenAI Python package with \"pip install openai\"\n",
        "\n",
        "API key is already provided but you can make your own at your own time"
      ],
      "metadata": {
        "id": "3MZMxTTpVPdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI # Required to access OpenAI's servers\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key='AIzaSyAEw2-vaCSmPBkVu-mEkY0PRAdJVmef92A', # Replace with your actual API key\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "def chatbot_conversation():\n",
        "    print(\"Hello! I'm your Personal chatbot. Type 'exit' to end the conversation.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        tokens = 100\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        print(user_input)\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"You are a helpful assistent that generates responses under {tokens} tokens.\"},\n",
        "                {\"role\": \"user\", \"content\": user_input}\n",
        "            ],\n",
        "            stream=False\n",
        "        )\n",
        "\n",
        "        chatbot_response = response.choices[0].message.content\n",
        "\n",
        "        print(\"Chatbot: \" + chatbot_response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot_conversation()"
      ],
      "metadata": {
        "id": "lFGP9UcrVXh3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}